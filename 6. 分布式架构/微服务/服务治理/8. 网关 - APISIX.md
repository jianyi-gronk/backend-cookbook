## 1. Nginx 痛点

- 在单体服务时代，使用 Nginx 可以应对大多数的场景，而到了云原生时代，Nginx 因为其自身架构的原因则会出现两个问题：
  - **首先是 Nginx 不支持集群管理**，即 Nginx 自身不能自动管理多个 Nginx 服务器的工作。几乎每家互联网厂商都有自己封装的 nginx 集群管理系统，系统虽然大同小异但是一直没有统一的方案
  - **其次是 nginx 不支持配置的热加载**。很多公司一旦修改了配置，重新加载 Nginx 的时间可能需要半个小时以上。并且在 Kubernetes 体系下，上游会经常发生变化，如果使用 Nginx 来处理就需要频繁重启服务，这对于企业是不可接受的
- 而 Kong 的出现则解决了 Nginx 的痛点，但是又带来了新的问题：
  - Kong 需要依赖于 PostgreSQL 或 Cassandra 数据库，这使 Kong 的整个架构非常臃肿，并且会给企业带来高可用的问题。如果数据库故障了，那么整个 API 网关都会出现故障
  - Kong 的路由使用的是遍历查找，当网关内有超过上千个路由时，它的性能就会出现比较急剧的下降
- 而 APISIX 的出现则解决了上述所有问题

## 2. Dubbo + APISIX

- Apache APISIX 是基于 Nginx/OpenResty + Lua 方案打造的一款 动态、实时、高性能 的 云原生 API 网关，提供了负载均衡、动态上游、灰度发布、服务熔断、身份认证、可观测性等丰富的流量管理功能
- 在实际应用场景中，Dubbo 一般会作为后端系统间 RPC 调用的实现框架，当需要提供 HTTP 接口给到前端时，会通过一个 “胶水层” 将 Dubbo Service 包装成 HTTP 接口，再交付到前端系统
- 得益于 Dubbo 的应用场景优势，APISIX 基于开源项目 tengine/mod_dubbo 模块为 Apache Dubbo 服务配备了 HTTP 网关能力。通过 dubbo-proxy 插件，可以轻松地将 Dubbo Service 发布为 HTTP 服务
  ![image](https://github.com/user-attachments/assets/d698a870-f432-42aa-b122-7647ffdd1e8d)

## 3. APISIX 架构

- APISIX 拥有优异的架构，现在很多应用都在向微服务、容器化迁移，形成新的云原生时代。云原生作为当下的技术潮流，将重写传统企业的技术架构。而 APISIX 自诞生之初就跟随技术潮流，并将其设计为云原生架构
  ![image](https://github.com/user-attachments/assets/81931665-99ab-4677-82b4-1f8f6f9691fb)
- 如上图所示，左右分别是 APISIX 的数据面（ Data Plane ）和控制面（ Control Plane ）：
  - 数据面：以 NGINX 的网络库为基础（ 未使用 NGINX 的路由匹配、静态配置和 C 模块 ），使用 Lua 和 NGINX 动态控制请求流量
  - 控制面：使用 etcd 来存储和同步网关的配置数据，管理员通过 Admin API 或者 Dashboard 可以在毫秒级别内通知到所有数据面节点。
- 在更新数据上，Kong 采用轮询数据库的方式，但是可能需要 5-10 秒才能获取到最新的配置；而 APISIX 则采用监听 etcd 的配置变更的方式，可以将时间控制在毫秒级，达到实时生效的效果
- 而且相比于 Nginx，由于 APISIX 和 etcd 均支持多点部署，因此在 APISIX 当前架构中，任何一个服务出现异常宕机等事故，都不会影响 APISIX 正常对外提供服务的能力

## 4. 使用示例

- [完整样例](https://www.aneasystone.com/archives/2023/02/apisix-notes.html)
- 首先下载 apisix-docker 仓库
  ```
  git clone https://github.com/apache/apisix-docker.git
  ```
- 这个仓库主要是用来指导用户如何使用 Docker 部署 APISIX 的，其中有一个 example 目录，是官方提供的入门示例，我们可以直接使用 docker-compose 运行它
  ```
  $ cd apisix-docker/example
  $ docker-compose up -d
  [+] Running 8/8
   - Network example_apisix                Created                         0.9s
   - Container example-web2-1              Started                         5.1s
   - Container example-web1-1              Started                         4.0s
   - Container example-prometheus-1        Started                         4.4s
   - Container example-grafana-1           Started                         5.8s
   - Container example-apisix-dashboard-1  Started                         6.0s
   - Container example-etcd-1              Started                         5.1s
   - Container example-apisix-1            Started                         7.5s
  ```
- 可以看到创建了一个名为 example_apisix 的网络，并在这个网络里启动了 7 个容器：
  - etcd：APISIX 使用 etcd 作为配置中心，它通过监听 etcd 的变化来实时更新路由
  - apisix：APISIX 网关
  - apisix-dashboard：APISIX 管理控制台，可以在这里对 APISIX 的 Route、Upstream、Service、Consumer、Plugin、SSL 等进行管理
  - prometheus：这个例子使用了 APISIX 的 prometheus 插件，用于暴露 APISIX 的指标，Prometheus 服务用于采集这些指标
  - grafana：Grafana 面板以图形化的方式展示 Prometheus 指标
  - web1：测试服务
  - web2：测试服务
- 部署之后可以使用 APISIX 的 Admin API 检查其是否启动成功：
  ```
  $ curl http://127.0.0.1:9180/apisix/admin/routes \
    -H 'X-API-KEY: edd1c9f034335f136f87ad84b625c8f1'
  {"list":[],"total":0}
  ```
- 目前还没有创建任何路由，所以 /apisix/admin/routes 接口返回的结果为空。可以使用 Admin API 和 Dashboard 两种方式来创建路由

## 5. 生态与社区

#### 5.1 完善的生态

- 下图为 APISIX 的生态图，从该图可以准确看到 APISIX 已经支持的 7 层协议有 HTTP(S)、HTTP2、Dubbo 和物联网协议 MQTT 等等，4 层协议有 TCP/UDP。右侧部分则是一些开源或者 SaaS 服务，比如 SkyWalking、Prometheus 、Vault 等等。而最下面则是比较常见的操作系统环境、云厂商和硬件环境。而作为一个开源软件，APISIX 也支持在 ARM64 的服务器上运行
  ![image](https://github.com/user-attachments/assets/ff6a2f10-bde5-4da6-a2a6-e517b757a259)
- APISIX 不仅支持众多协议与操作系统，而且也支持多语言编程插件。APISIX 诞生之初仅支持使用 Lua 语言编写插件，这种情况下就需要开发者掌握 Lua 和 NGINX 相关的技术栈。然而 Lua 和 NGINX 属于相对小众的技术，开发者很少。因此我们在 APISIX 上支持了多语言开发插件，目前已经正式支持了 Java、Golang、Node.js、Python 等语言
  ![image](https://github.com/user-attachments/assets/b650c6c1-d390-41c0-8abf-13326a43dd9a)

#### 4.2 活跃的社区

- 下图是贡献者增长曲线，其中横坐标代表时间线，纵坐标代表贡献者总数。我们可以看到 APISIX 和 Kong 这两个项目相对更活跃，APISIX 的增长速度从开源第一天就保持着非常不错的增长率，在以接近 Kong 两倍的速度快速成长，并且贡献者数量已经远远超过了 Kong，由此可见 APISIX 受欢迎程度。当然评价一个项目活跃度还有很多其他方法，比如查看每月活跃 Issue、PR 总数等方式，值得高兴的是 APISIX 在这些方面也是一骑绝尘
  ![image](https://github.com/user-attachments/assets/862afb5f-5ed9-4610-9424-58070df8bcd4)

## 1. 微服务网关

- 微服务网关属于业务网关，和 Nginx 这样的流量网关存在差异
- Nginx 网关
  - 流量网关：专注于全局性、与具体业务无关的策略，如反向代理、负载均衡、静态资源处理、SSL 加密、全局限流 等
  - 核心功能：高性能 HTTP 服务器、反向代理、负载均衡、安全控制（ 如黑白名单 ）
- 微服务网关
  - 业务网关：**针对微服务架构设计，提供动态路由、鉴权、限流、熔断等与业务紧密相关的功能**
  - 核心功能：API 管理、协议转换（ 例如，HTTP 和 RPC 协议 ）、服务发现、过滤器链（ 如请求头修改、重试逻辑 ）等
- 流量网关和业务网关是可以同时使用的，比如请求先通过流量网关过滤，再通过业务网关分发处理

## 2. 协议转换

- 当客户端不支持 RPC 协议时，或者需要将 RPC 服务暴露给 Web 应用程序时，需要一种将 RESTful API 转换为 RPC 的方式，核心是将 RESTful API 转换为 RPC 请求，然后将 RPC 响应转换为 RESTful API
- 通常有两种方式，go-zero 中称为 protoDescriptor 和 grpcReflection

#### 2.1 protoDescriptor

- 实现流程：
  - 定义 .proto 文件：编写服务接口
  - 生成描述文件：通过 protoc 编译生成 .pb 或 .descriptor 文件（ 二进制格式的接口元数据 ）
  - 网关加载描述文件：API 网关读取 .desc 文件，解析出服务方法和 REST 映射规则。
  - 运行时映射：网关根据描述文件，将 HTTP 请求转换为对应的 RPC 请求
- 特点：
  - 依赖编译阶段：需提前生成 .desc 文件，服务端和网关均需依赖此文件
  - 静态绑定：接口元数据在编译后固定，修改 .proto 需重新生成并部署文件
  - 适用场景：需要严格版本控制或离线环境

#### 2.2 grpcReflection

- 实现流程：
  - 和 protoDescriptor 方式类似，不同的是，grpcReflection 方式不需要通过 protoc 将 proto 生成为 pb 文件，而是通过 rpc 的反射机制，直接从 rpc server 中获取 proto 文件，然后在 gateway 中去引用该 proto 文件做 rest-rpc 的规则映射
- 特点：
  - 无需预生成文件：直接通过反射 API 从运行中的 RPC Server 获取元数据
  - 动态更新：若服务端接口变更（如新增方法），网关无需重启即可感知
  - 适用场景：开发调试、快速迭代的环境
