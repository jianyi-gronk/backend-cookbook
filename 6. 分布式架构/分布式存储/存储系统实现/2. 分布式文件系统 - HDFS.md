## 1. 基础概念

- HDFS 是 Hadoop 的分布式文件存储系统模块，是根据 GFS 的原理开发的，是 GFS 的简化版
- 虽然 Google 发表了 MapReduce、GFS 和 BigTable 三篇技术论文，但没有开源具体的技术实现，所以其他互联网公司只能根据这三篇技术论文中的相关原理，搭建自己的分布式计算系统。例如，Hadoop 采用了 MapReduce 打造了分布式计算框架，并根据 GFS 开发了 HDFS 分布式文件系统，根据 BigTable 开发了 HBase 数据存储系统
- 其中，HDFS 虽然和 GFS 原理相同，但运算速度上达不到 Google 论文中的标准，并且在并发写的处理上，采用了一些简化的做法。尽管如此， HDFS 算是开源分布式文件系统中最完整实现了 GFS 论文中的概念模型。Hadoop 也由于其开源特性，使得它成为分布式计算系统事实上的国际标准

## 2. GFS 与 HDFS 的异同

#### 2.1 相同点

- 都采用 单一主控机 加 多台工作机 的模式，由一台主控机（ Master ）存储系统全部元数据，并实现数据的分布、复制、备份决策，主控机还实现了元数据的 checkpoint 和操作日志记录及回放功能。工作机存储数据，并根据主控机的指令进行数据存储、数据迁移和数据计算等
- 都通过数据分块和复制（ 多副本，一般是 3 ）来提供更高的可靠性和更高的性能。当其中一个副本不可用时，系统都提供副本自动复制功能。同时，针对数据读多于写的特点，读服务被分配到多个副本所在机器，提供了系统的整体性能
- 都提供了一个树结构的文件系统，实现了类似与 Linux 下的文件复制、改名、移动、创建、删除操作以及简单的权限管理等

#### 2.2 不同点

- GFS 支持多客户端并发 Append 模型，允许文件被多次或者多个客户端同时打开以追加数据；HDFS 文件只允许一次打开并追加数据，客户端先把所有数据写入本地的临时文件中，等到数据量达到一个块的大小（ 通常为 64MB ），再一次性写入 HDFS 文件
- GFS 采用主从模式备份 Master 的系统元数据，当主 Master 失效时，可以通过分布式选举备机接替，继续对外提供服务；而 HDFS 的 Master 的持久化数据只写入到本机，可能采用磁盘镜像作为预防，出现故障时需要人工介入
- GFS 支持数据库快照，而 HDFS 不支持
- GFS 写入数据时，是实时写入到物理块；而 HDFS 是积攒到一定量，才持久化到磁盘
