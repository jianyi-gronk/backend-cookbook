## 1. 基础概念

- Apache Hadoop 是一种专用于批处理的处理框架。Hadoop 是首个在开源社区获得极大关注的大数据框架。基于谷歌有关海量数据处理所发表的多篇论文与经验的 Hadoop 重新实现了相关算法和组件堆栈，让大规模批处理技术变得更易用
- Hadoop 框架主要由 4 个模块组成，这四个模块协同运行以形成 Hadoop 生态系统：
  - HDFS：
    - 是一种分布式文件系统，可以对集群节点之间的存储和复制进行协调，它确保了当某些节点故障发生后数据依然可用
    - 可将其作为数据来源，或是存储中间态的处理结果，亦或是存储计算的最终结果
  - YARN：
    - 是 Yet Another Resource Negotiator（ 另一个资源管理器 ）的缩写，可充当 Hadoop 堆栈的集群协调组件，该组件负责协调并管理底层资源和调度作业的运行
  - MapReduce：
    - MapReduce 是 Hadoop 的原生批处理引擎
  - Hadoop Common：
    - Hadoop Common 包括其他 Hadoop 模块使用和共享的库和实用程序
- 可以把 Yarn 理解为相当于一个分布式的操作系统，Yarn 为这些程序分配运算所需的资源（ 内存、cpu ），而 mapreduce 等运算程序则相当于运行于操作系统之上的应用程序（ 需要用户自己编写 map 和 reduce 函数 ），HDFS 则是这个平台的底层内部实现
- Hadoop 支持在硬件集群中分布数据集。处理是同时在多台服务器上并行执行的。软件客户端将数据输入 Hadoop，HDFS 会处理元数据和分布式文件系统，然后 MapReduce 会处理并转换数据，最后 YARN 会在计算集群中划分作业

#### 1.1 优点

- 可伸缩性
  - Hadoop 是快速存储和处理海量数据的主要工具之一，它通过使用分布式计算模型来实现这一点，该模型支持快速处理可通过添加计算节点快速扩缩的数据
- 费用低
  - 作为一个可以在普通商品硬件上运行并且拥有庞大的工具生态系统的开源框架，Hadoop 是存储和管理大数据的低成本方案
- 灵活性
  - Hadoop 可提供数据存储的灵活性，因为数据在存储之前不需要预处理，这意味着组织可以存储任意数量的数据，并在以后使用
- 弹性
  - 作为一种分布式计算模型，Hadoop 支持容错和系统弹性
  - 这意味着，如果其中一个硬件节点发生故障，作业会重定向到其他节点。存储在一个 Hadoop 集群中的数据会在系统内的其他节点上复制，以防范硬件或软件故障

#### 1.2 缺点

- MapReduce 复杂性和限制
  - 作为一个文件密集型系统，MapReduce 可能难以用于复杂的作业（ 例如交互式分析任务 ）
  - MapReduce 函数也需要用 Java 编写，并且可能需要很长的学习时间。MapReduce 生态系统非常庞大，许多组件对应不同的功能，因此很难确定要使用哪些工具
- 安全
  - 由于 Hadoop 需要处理如此庞大的数据集，因此可能会出现数据敏感和 保护方面的问题
  - 不过关于身份验证、加密、审核和预配工具的生态系统已经兴起，可帮助开发者保护 Hadoop 中的数据
- 治理和管理
  - Hadoop 没有太多强大的数据管理和治理工具，也不适用于数据质量和标准化

#### 1.3 Hadoop 常用工具

- Hadoop 拥有庞大的开源工具生态系统，可增强和扩展核心模块的功能。可用于 Hadoop 的一些主要软件工具包括：
  - Apache Hive：一种数据仓库，允许程序员使用名为 HiveQL（ 类似于 SQL ）的查询语言处理 HDFS 中的数据
  - Apache HBase：一种开源非关系型分布式数据库，通常与 Hadoop 搭配使用
  - Apache Pig：一种在 MapReduce 上用作抽象层的工具，用于分析大量数据，并启用过滤、排序、加载和加入等功能
  - Apache Impala：一种用于大规模并行处理的开源 SQL 查询引擎，常与 Hadoop 搭配使用
  - Apache Sqoop：一种命令行界面应用，用于在关系型数据库和 Hadoop 之间高效传输批量数据
  - Apache ZooKeeper：一种开源服务器，能够在 Hadoop 中实现可靠的分布式协调，是一项用于 维护配置信息、命名、提供分布式同步和提供群组服务 的服务
  - Apache Oozie：Hadoop 作业的工作流调度器

#### 1.4 常见用途

- 分析和大数据
  - 许许多多的公司和组织将 Hadoop 用于研究、生产数据处理和分析，这些任务需要处理 TB 级或 PB 级的大数据、存储各种数据集以及进行数据并行处理
- 数据存储和归档
  - 由于 Hadoop 支持在商品硬件上进行大容量存储，因此它适合作为各类数据的低成本存储方案，例如事务、点击流或传感器和机器数据
- 数据湖
  - 由于 Hadoop 可以帮助存储数据而无需预处理，因此可用于对存储大量未优化数据的数据湖进行补充
- 营销分析
  - 营销部门通常使用 Hadoop 来存储和分析客户关系管理（ CRM ）数据
- 风险管理
  - 银行、保险公司和其他金融服务公司使用 Hadoop 构建风险分析和管理模型
- AI 和机器学习
  - Hadoop 生态系统有助于为机器学习应用处理数据和模型训练操作

## 2. HDFS（ Hadoop Distributed File System ）

[细节](https://www.51cto.com/article/681680.html)

#### 2.1 概念

- HDFS 是 Hadoop 的主要组件之一，MapReduce 则为海量的数据提供了计算，而 HDFS 为海量的数据提供了存储
- HDFS 是一种分布式文件系统，用于处理在商业硬件上运行的大型数据集。可以将单个 Apache Hadoop 集群扩展到数百 （ 甚至数千 ）个节点
- 注意，HDFS 不应与 Apache HBase 混淆或被 Apache HBase 取代，Apache HBase 是一个面向列的非关系数据库管理系统，它位于 HDFS 之上，可以通过其内存处理引擎更好地支持实时数据需求
- HDFS 的底层用到了分布式数据存储中的复制和分片概念

#### 2.2 作用

- 从硬件故障中快速恢复
  - 因为一个 HDFS 实例可能由数千台服务器组成，所以至少有一台服务器出现故障是不可避免的。 HDFS 可检测故障并自动快速恢复
- 访问流数据
  - HDFS 更适用于批处理而不是交互式使用，因此设计中的重点是高数据吞吐率，以适应对数据集的流式访问
- 容纳大数据集
  - HDFS 适用于数据集大小通常为 GB 到 TB 的应用程序。 HDFS 提供高聚合数据带宽，可以扩展到单个集群中的数百个节点
- 可移植性
  - 为了便于采用，HDFS 设计为可跨多个硬件平台移植，并与各种底层操作系统兼容

#### 2.3 架构模型

- 在 HDFS 1.X 时，NameNode 是 HDFS 集群中可能发生单点故障的节点，集群中只有一个 NameNode，一旦 NameNode 宕机，整个集群将处于不可用的状态
- 在 HDFS 2.X 时，HDFS 提出了高可用的方案，解决了 HDFS 1.X 时的单点问题。即在一个集群中，会配置两个 NameNode，一个是 Active NameNode（ 主 ），一个是 Stadby NameNode（ 备 ）。主节点负责执行所有修改命名空间的操作，备节点则执行同步操作，以保证与主节点命名空间的一致性。架构模型如下图所示：
  ![image](https://github.com/user-attachments/assets/f2b679c0-9a33-452f-9ddb-3f8b21719b86)

## 3. YARN

#### 3.1 概念

- Yarn 是一种新的 Hadoop 资源管理器，它是一个通用资源管理系统和调度平台，可为上层应用提供统一的资源管理和调度，提高了集群在利用率、资源统一管理和数据共享等方面
- Yarn 并不清楚用户提交的程序的运行机制，Yarn 只提供运算资源的调度（ 用户程序向 yarn 申请资源，yarn 就负责分配资源 ）
- 与运行的用户程序完全解耦，意味着 yarn 上可以运行各种类型的分布式运算程序，比如 mapreduce、storm，spark，tez 等。spark、storm 等运算框架都可以整合在 yarn 上运行，只要他们各自的框架中有符合 yarn 规范的资源请求机制即可
- yarn 成为一个通用的资源调度平台。企业中以前存在的各种运算集群都可以整合在一个物理集群上，提高资源利用率，方便数据共享

#### 3.2 结构

- YARN 是一个资源管理、任务调度的框架，主要包含三大模块：
  - ResourceManager（ RM ）负责所有资源的监控、分配和管理，一个集群只有一个
  - NodeManager（ NM ）负责每一个节点的维护，一个集群有多个
  - ApplicationMaster（ AM ）负责每一个具体应用程序的调度和协调，一个集群有多个
- 对于所有的 applications，RM 拥有绝对的控制权和对资源的分配权。而每个 AM 则会和 RM 协商资源，同时和 NodeManager 通信来执行和监控 task
- 结构图
  ![image](https://github.com/user-attachments/assets/010b0cba-4582-4430-97b1-7e74a7549848)

#### 3.3 三大组件 —— ResourceManager

- ResourManager 负责整个集群的资源管理和分配，是一个全局的资源管理系统
- NodeManager 以心跳的方式向 ResourceManager 汇报资源使用情况（ 主要是 CPU 和 内存的使用情况 ）。RM 只接受 NM 的资源回报信息，对于具体的资源处理则交给 NM 自己处理
- Yarn Scheduler 根据 application 的请求为其分配资源，不负责 application job 的监控、追踪、运行状态反馈、启动等工作

#### 3.4 三大组件 —— NodeManager

- NodeManager 是每个节点上的资源和任务管理器，它是管理这台机器的代理，负责该节点程序的运行，以及该节点资源的管理和监控。YARN 集群每个节点都运行一个 NodeManager
- NodeManager 定时向 ResourceManager 汇报本节点资源（ CPU、内存 ）的使用情况和 Container 的运行状态。当 ResourceManager 宕机时 NodeManager 自动连接 RM 备用节点
- NodeManager 接收并处理来自 ApplicationMaster 的 Container 启动、停止等各种请求

#### 3.5 三大组件 —— ApplicationMaster

- 用户提交的每个应用程序均包含一个 ApplicationMaster，它可以运行在 ResourceManager 以外的机器上
- 负责与 RM 调度器协商以获取资源（ 用 Container 表示 ）
- 将得到的任务进一步分配给内部的任务（ 资源的二次分配 ）
- 与 NM 通信以 启动 或 停止 任务
- 监控所有任务运行状态，并在任务运行失败时重新为任务申请资源以重启任务
- 当前 YARN 自带了两个 ApplicationMaster 实现
  - 一个是用于演示 AM 编写方法的实例程序 DistributedShell，它可以申请一定数目的 Container 以并行运行一个 Shell 命令或者 Shell 脚本
  - 另一个是运行 MapReduce 应用程序的 AM—MRAppMaster
- 注：RM 只负责监控 AM，并在 AM 运行失败时候启动它。RM 不负责 AM 内部任务的容错，任务的容错由 AM 完成

#### 3.6 Yarn 运行流程

- 工作流程图
  ![image](https://github.com/user-attachments/assets/a5602ee6-1187-463c-bd1d-785e50253b46)
  1. client 向 RM 提交应用程序，其中包括启动该应用的 ApplicationMaster 的必须信息，例如 ApplicationMaster 程序、启动 ApplicationMaster 的命令、用户程序等
  2. ResourceManager 启动一个 container 用于运行 ApplicationMaster
  3. 启动中的 ApplicationMaster 向 ResourceManager 注册自己，启动成功后与 RM 保持心跳
  4. ApplicationMaster 向 ResourceManager 发送请求，申请相应数目的 container
  5. 申请成功的 container，由 ApplicationMaster 进行初始化。container 的启动信息初始化后，AM 与对应的 NodeManager 通信，要求 NM 启动 container
  6. NM 启动启动 container
  7. container 运行期间，ApplicationMaster 对 container 进行监控。container 通过 RPC 协议向对应的 AM 汇报自己的进度和状态等信息
  8. 应用运行结束后，ApplicationMaster 向 ResourceManager 注销自己，并允许属于它的 container 被收回
- 具体流程图
  ![image](https://github.com/user-attachments/assets/205b6631-539d-48f1-abc2-556144a72b78)

## 4. 批处理

- Hadoop 的批处理功能来自 MapReduce 引擎，MapReduce 的处理技术符合使用键值对的 map、shuffle、reduce 算法要求
- 基本处理过程包括：
  - 从 HDFS 文件系统读取数据集
  - 将数据集拆分成小块并分配给所有可用节点
  - 针对每个节点上的数据子集进行计算（ 计算的中间态结果会重新写入 HDFS ）
  - 重新分配中间态结果并按照键进行分组
  - 通过对每个节点计算的结果进行汇总和组合对每个键的值进行 Reduce
  - 将计算而来的最终结果重新写入 HDFS
