[参考这篇的，原文有图，更详细](https://juejin.cn/post/6963931777962344455)

## 1. 单工通信，半双工通信，双工通信

#### 1.1 单工通信

- **单工通信只能在一个方向上进行数据传输**
- 在单工通信中，发送方和接收方的角色是固定的，即一方始终是发送方，另一方始终是接收方。在任何时候，数据只能从发送方传输到接收方，而不能反向传输。这意味着通信双方不能同时发送和接收数据
- 单工通信的优点是简单易实现，但缺点是通信效率较低，因为无法实现双向通信
- 典型例子是广播系统，如收音机或电视。在这些系统中，信号始终从广播台（ 发送方 ）传输到用户设备（ 接收方 ），而用户设备无法将信号传回广播台

#### 1.2 半双工通信

- **半双工通信允许数据在两个方向上进行传输，但不能同时进行**
- 在半双工通信中，通信双方可以充当发送方和接收方，但在任何时候，只能有一个方向上的数据传输。这意味着，一旦一方开始发送数据，另一方必须停止发送数据并转换为接收模式
- 半双工通信比单工通信更灵活，但仍然存在通信效率的问题，因为通信双方不能同时发送和接收数据
- 典型例子是对讲机，在对讲机通信中，当一方按下讲话按钮并开始发送信号时，另一方必须等待并接收信号。在接收信号的过程中，另一方无法发送信号

#### 1.3 双工通信

- **双工通信允许数据在两个方向上同时进行传输**
- 在双工通信中，通信双方可以同时充当发送方和接收方，实现同时发送和接收数据。这意味着，通信双方可以在任何时候互相发送和接收数据，而无需等待对方
- 双工通信的优点是通信效率高，实现了真正的双向通信，但实现双工通信的技术要求相对较高
- 典型例子是电话，在电话通信中，通话双方可以同时说话和听对方说话，而无需等待对方停止讲话

## 2. HTTP1.0 协议

#### 2.1 基础介绍

- **HTTP1.0 是 单工通信，也是半双工通信，取决于如何去看待**
  - 在 HTTP1.0 中，客户端需要等待服务器的响应，然后才能发送下一个请求。这意味着，请求和响应在同一时间只能有一个在传输，它们之间是互斥的
  - 如果周期定义为一次 请求 或 响应 周期
    - 那么在一个周期内，它们之间的通信是单向的，发送方和接受方是固定的，所以是单工通信
  - 如果周期定义为整个 HTTP 通信周期
    - 那么在一个周期内，发送方既是客户端也是服务器，接受方同理，不是固定的，所以是半双工通信
- **HTTP1.0 是 无状态 无连接 的**
  - 无连接
    - 规定浏览器和服务器保持短暂的连接，浏览器的每次请求都需要与服务器建立一个 TCP 连接，服务器处理完成后立即断开 TCP 连接
  - 无状态
    - 服务器不跟踪每个客户端也不记录过去的请求

#### 2.2 HTTP1.0 缺点

- **无法复用连接**
  - 每次发送请求的时候，都需要进行一次 TCP 连接，而 TCP 的连接释放（ 三握四挥 ）过程又是比较费时费事的，这种无连接的特性会导致网络的利用率非常低
- **队头堵塞**
  - 由于 HTTP1.0 规定下一个请求必须在前一个请求响应到达之后才能发送。假设一个请求响应一直不到达，那么下一个请求就不发送，就到导致阻塞后面的请求

## 3. HTTP1.1 协议

#### 3.1 基础介绍

- **HTTP1.1 是 半双工通信**
  - 不再是 请求 - 响应 - 请求 - 响应 - ...，有可能是 请求 - 请求 - 响应 - 请求 - 响应 - 响应。所以不能再把周期定义为一次 请求 或 响应 周期，因此 发送方 和 接受方 一直在变化，所以是半双工通信
- HTTP1.1 和 HTTP1.0 本质还是非常相近，当把 HTTP1.1 的请求或者响应中的 Connection 设置成 close，关闭长连接，其实就相当于 HTTP1.0，毕竟 **像 管道化 这种特性都是依托于 长连接**

#### 3.2 优化 HTTP1.0 方面

- **长连接（ 解决无法复用连接 ）**
  - HTTP1.1 增加了一个 Connection 字段，通过设置 keep-alive（ 默认已设置 ）可以保持连接不断开，避免了每次客户端与服务器请求都要重复建立释放 TCP 连接，提高了网络的利用率
  - 如果客户端想关闭 HTTP 连接，可以在请求头中携带 Connection: close 来告知服务器关闭请求
  - 若开启 keep-alive，在一次 HTTP 请求中，服务器进行响应后，不再直接断开 TCP 连接，而是将 TCP 连接维持一段时间。在这段时间内，如果同一客户端再次向服务端发起 HTTP 请求，便可以复用此 TCP 连接，向服务端发起请求，并重置 timeout 时间计数器，在接下来一段时间内还可以继续复用。这样无疑省略了反复创建和销毁 TCP 连接的损耗
- **支持请求管道化（ 解决队头堵塞 ）**
  - HTTP1.1 的 长连接 是 请求管道化 的前提
  - 管线化使得请求能够在一次连接内进行 “并行” 传输，但并没有真正实现并行传输，仍然存在堵塞问题

#### 3.3 HTTP1.1 缺点

- **仍然存在堵塞问题**
  - 在 HTTP1.0 中，每一个请求都得等前面请求到达才能发送，相当于一个请求队列
  - 而 HTTP1.1 可以即使前面的请求没有到达，仍可以发送请求，但是响应必须按照请求的顺序，先后发送响应，以保证客户端能区分不同请求对应的响应，相当于一个响应队列
  - 即 **从原本在请求队列中等待，变成在响应队列中等待**，还是存在堵塞，仍没有实现 “并行”

## 4. HTTP2 协议

#### 4.1 基础介绍

- **HTTP2 是 全双工通信**
  - 因为多路复用，服务器推送等功能的实现，可以真正的并行传输
- HTTP2 不是必须要运行在 HTTPS 上的
  - 虽然 HTTP2 的设计初衷是与 TLS/SSL 结合使用以提供更安全的通信，但它也可以在非安全的环境下工作，即纯文本的 HTTP 连接
  - 这种情况下，称为 HTTP/2 Clear Text（ H2C ）。H2C 使用明文传输，没有加密和身份验证，因此在安全性方面相对较弱
- 目前主流浏览器，chrome，火狐等都已经公开宣布只支持加密的 HTTP2，所以目前互联网上能见到的 HTTP2 基本都是基于 HTTPS 协议，HTTPS 保证了传输的安全性却造成了额外的性能开销，而 HTTP2 的出现正好通过多路复用，头部压缩等特性大大的提升了传输性能

#### 4.2 优化 HTTP1.1 方面

- **二进制分帧**
  - HTTP2 采用二进制格式传输数据，而非 HTTP1.x 的文本格式，二进制协议解析起来更高效
  - HTTP1.x 的请求和响应报文，都是由 起始行，首部 和 实体正文（ 可选 ）组成，各部分之间以 文本换行符 分隔。HTTP2 将请求和响应数据分割为更小的帧，并且它们采用二进制编码
- **多路复用**
  - HTTP2 实现了真正的并行传输，它能在一个 TCP 上进行任意数量 HTTP 请求，这个强大的功能基于 “二进制分帧” 特性
    - 数据流以消息的形式发送，而消息又由一个或多个帧组成，多个帧之间可以乱序发送，因为根据帧首部的流标识可以重新组装
    - 同域名下的所有通信都在单个 TCP 连接中完成，消除了因多个 TCP 连接而带来的延时和内存消耗
    - 单个连接可以承载任意数量的双向数据流，可以并行交错地请求和响应，之间互不干扰
    - 在 HTTP2 中，每个请求都可以带一个 31bit 的优先值，0 表示最高优先级，数值越大优先级越低，通过优先级，客户端和服务器就可以在处理不同的流时采取不同的策略，以最优的方式发送流、消息和帧
  - 总结：因为 HTTP1.1 是基于文本分割解析的协议，也没有序号，如果多路复用会导致顺序错乱，HTTP2 则用帧的方式，等于切成一块块，每一块都有对应的序号，所以可以实现多路复用
- **服务器推送**
  - 服务端可以在发送页面 html 时，主动推送其它资源，而不用等到浏览器解析到相应位置，发起请求再响应；服务端还可以主动把 js 和 css 文件推送给客户端，而不需要客户端解析 html 时再发送这些请求
  - 服务端可以主动推送，客户端也有权利选择是否接收，如果服务端推送的资源已经被浏览器缓存过，浏览器可以通过发送 RST_STREAM 帧来拒收，主动推送也遵守同源策略，服务器不会随便推送第三方资源给客户端
- **头部压缩**
  - 在 HTTP1.x 中，头部元数据都是以纯文本的形式发送的，通常会给每个请求增加 500~800 字节的负荷
  - 比如说 cookie，默认情况下，浏览器会在每次请求的时候，把 cookie 附在 header 上面发送给服务器（ 由于 cookie 比较大且每次都重复发送，一般不存储信息，只是用来做状态记录和身份认证 ）
  - HTTP2 使用 encoder 来减少需要传输的 header 大小，通讯双方各自 cache 一份 header fields（ 头部字段 ）表，既避免了重复 header 的传输，又减小了需要传输的大小，高效的压缩算法可以很大的压缩 header，减少发送包的数量从而降低延迟

#### 4.4 HTTP2 缺点

- **仍然可能存在堵塞问题**
  - 因为 TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且有序的，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经被接收了，应用层也无法从内核中读取到这部分数据，从 HTTP 视角看，就是请求被阻塞了

## 5. HTTP3

- HTTP2 虽然解决了很多之前旧版本的问题，但是它还是存在一个巨大的问题，主要是底层支撑的 TCP 协议造成的
  - 之前提到 HTTP2 使用了多路复用，一般来说同一域名下只需要使用一个 TCP 连接。但当这个连接中出现了丢包的情况，那就会导致 HTTP2 的表现情况反倒不如 HTTP1.1
  - 因为在出现丢包的情况下，整个 TCP 都要开始等待重传，也就导致了后面的所有数据都被阻塞了。但是对于 HTTP1.1 来说，可以开启多个 TCP 连接，出现这种情况反到只会影响其中一个连接，剩余的 TCP 连接还可以正常传输数据
  - 但去修改 TCP 协议，其实这已经是一件不可能完成的任务了，因为 TCP 存在的时间实在太长，已经充斥在各种设备中，并且这个协议是由操作系统实现的，更新起来不大现实
- 所以 Google 就自己架起炉灶搞了一个基于 UDP 协议的 QUIC 协议，并且使用在了 HTTP3 上，HTTP3 之前名为 HTTP-over-QUIC，从这个名字中我们也可以发现，HTTP3 最大的改造就是使用了 QUIC（ quick udp internet connection，快速 UDP 互联网连接 ）
