## 1. 缓存

- 随着互联网的普及，内容信息越来越复杂，用户数和访问量越来越大，应用需要支撑更多的并发量，同时应用服务器和数据库服务器所做的计算也越来越多。但是往往我们的应用服务器资源是有限的，数据库每秒能接受的请求次数也是有限的（ 或者文件的读写也是有限的 ）
- 如何能够有效利用有限的资源来提供尽可能大的吞吐量? 一个有效的办法就是引入缓存，打破标准流程，每个环节中请求可以从缓存中直接获取目标数据并返回，从而减少计算量，有效提升响应速度，让有限的资源服务更多的用户
- 如互联网应用一般流程图所示，缓存的使用可以出现在 1 ～ 4 的各个环节中，每个环节的缓存方案与使用各有特点
  ![image](https://github.com/user-attachments/assets/21383b03-b9f3-4581-9e34-9c6651e4ee47)
- 其实我们在很多地方不经意间都使用了缓存，比如
  - 我们从硬盘读数据的时候，其实操作系统还额外把附近的数据都读到了内存里
  - 例如，CPU 在从内存里读数据的时候，也额外读了许多数据到各级 cache 里
  - 各个输入输出之间用 buffer 保存一批数据统一发送和接受，而不是一个 byte 一个 byte 的处理
  - 浏览器会缓存页面的元素，这样在重复访问网页时，就避开了要从互联网上下载数据（ 例如大图片 ）
  - web 服务会把静态的东西提前部署在 CDN 上，这也是一种缓存
  - 数据库会缓存查询，所以同一条查询第二次就是要比第一次快内存数据库（ 如 redis ）选择把大量数据存在内存而非硬盘里，这可以看作是一个大型缓存，只是把整个数据库缓存了起来
  - 应用程序把最近几次计算的结果放在本地内存里，如果下次到来的请求还是原请求，就跳过计算直接返回结果

## 2. 命中率

- 命中率 = 命中数 /（ 命中数 + 没有命中数 ）
- 影响缓存命中率的因素：
  - 业务场景和业务需求缓存通常适合**读多写少**的业务场景，反之的使用意义并不多，命中率会很低。业务需求也决定了实时性的要求，直接影响到过期时间和更新策略，**实时性要求越低越适合缓存**
  - 缓存的设计（ 策略和粒度 ）通常情况下**缓存的粒度越小，命中率越高**
    - 比如说缓存一个用户信息的对象，只有当这个用户的信息发生变化的时候才更新缓存
    - 而如果是缓存一个集合的话，集合中任何一个对象发生变化都要重新更新缓存
    - 当数据发生变化时，直接更新缓存的值比移除缓存或者让缓存过期它的命中率更高，不过这个时候系统的复杂度过高
  - 缓存的容量和基础设施缓存的容量有限就会容易引起缓存的失效和被淘汰
    - 目前多数的缓存框架和中间件都采用 LRU 这个算法
    - 缓存的技术选型也是至关重要的，比如采用本地内置的应用缓存，就比较容易出现单机瓶颈。而采用分布式缓存就更加容易扩展。所以需要做好系统容量规划，系统是否可扩展
  - 最大空间
    - 缓存最大空间一旦缓存中元素数量超过这个值（ 或者缓存数据所占空间超过其最大支持空间 ），那么将会触发缓存启动清空策略根据不同的场景合理的设置最大元素值往往可以一定程度上提高缓存的命中率，从而更有效的利用缓存

## 3. 缓存介质

- 虽然从硬件介质上来看，无非就是内存和硬盘两种，但从技术上，可以分成内存、硬盘文件、数据库
- 内存：将缓存存储于内存中是最快的选择，无需额外的 I/O 开销，但是内存的缺点是没有持久化落地物理磁盘，一旦应用异常 break down 而重新启动，数据很难或者无法复原
- 硬盘：一般来说，很多缓存框架会结合使用内存和硬盘，在内存分配空间满了或是在异常的情况下，可以被动或主动的将内存空间数据持久化到硬盘中，达到释放空间或备份数据的目的
- 数据库：数据库也有很多种类型，像那些不支持 SQL，只是简单的 key-value 存储结构的特殊数据库（ 如 BerkeleyDB 和 Redis ），响应速度和吞吐量都远远高于我们常用的关系型数据库等

## 4. 缓存淘汰算法

- FIFO：最先进入缓存的数据，在缓存空间不足时被清除，为了保证最新数据可用，保证实时性
- LFU（ Least Frequently Used ）：最近最不常用，基于访问次数，去除命中次数最少的元素，保证高频数据有效性
- LRU（ Least Recently Used ）：最近最少使用，基于访问时间，在被访问过的元素中去除最久未使用的元素，保证热点数据的有效性
- 过期时间：设置过期时间，过期就淘汰
- 随机：缓存过多时，随机淘汰缓存数据

## 5. 高并发缓存问题

#### 5.1 缓存穿透

- 导致原因
  - 指查询一个数据库一定不存在的数据。正常的使用缓存流程大致是，数据查询先进行缓存查询，如果 key 不存在或者 key 已经过期，再对数据库进行查询，并把查询到的对象，放进缓存。如果数据库查询对象为空，则不放进缓存
  - 但是这种方法存在一个问题，比如我传一个用户 id 为 - 1，这个用户 id 在缓存里面是肯定不存在的，所以会去数据库里面查询，如果有搞事情的人，大批量请求并传用户 id 为 - 1，那就和没用缓存一样，导致数据库压力过大而崩溃
- 解决方案
  - 方法一：在接口层增加校验，不合法的参数直接返回。不相信任务调用方，根据自己提供的 API 接口规范来，作为被调用方，要考虑可能任何的参数传值
  - 方法二：缓存空对象。即在缓存查不到，DB 中也没有的情况，可以将对应的 key 的 value 写为 null，或者其他特殊值写入缓存，同时将过期失效时间设置短一点，以免影响正常情况。这样是可以防止反复用同一个 ID 来暴力攻击
  - 方法三：正常用户是不会这样暴力功击，只有是恶意者才会这样做，可以在网关 NG 作一个配置项，为每一个 IP 设置访问阈值
  - 方法四：高级用户布隆过滤器（ Bloom Filter ），这个也能很好地防止缓存穿透。原理就是利用高效的数据结构和算法快速判断出你这个 Key 是否在 DB 中存在，不存在你 return 就好了，存在你就去查了 DB 刷新 KV 再 return

#### 5.2 缓存雪崩

- 导致原因
  - 在同一个时间，缓存大批量的失效，然后所有请求都打到 DB 数据库，导致 DB 数据库直接扛不住崩了
  - 比如，电商首页缓存，如果首页的 key 全部都在某一时刻失效，刚好在那一时刻有秒杀活动，那这样的话就所有的请求都被打到了 DB。并发大的情况下 DB 必然扛不住，没有其他降级之类的方案的话，DBA 也只能重启 DB，但是这样又会被新的流量搞挂
- 解决方案
  - 批量往 redis 存数据的时候，把每个 key 的失效时间加上个随机数，比如 1-5 分钟随机，这样的话就能保证数据不会在同一个时间大面积失效

#### 5.3 缓存击穿

- 导致原因
  - 缓存击穿跟缓存雪崩有些类似，雪崩是大面积缓存失效，导致数据库崩溃，而缓存击穿是一个 key 是热点，不停地扛住大并发请求，全都集中访问此 key, 而当此 key 过期瞬间，持续的大并发就击穿缓存，全都打在 DB 上。就又引发雪崩的问题
- 解决方案
  - 方法一：把这个热点 key 设置为永久有效
  - 方法二：使用互斥锁，这是比较常用的方法，简单地来说，就是在缓存失效的时候（ 判断拿出来的值为空 ），不是立即去查询数据库，而是先使用缓存工具的某些带成功操作返回值的操作（ 比如 Redis 的 SETNX 或者 Memcache 的 ADD ）去 set 一个 mutex key，当操作返回成功时，再进行查询数据库的操作并回设缓存；否则，就重试整个 get 缓存的方法

#### 5.4 缓存双写一致性

- 导致原因：
  - 缓存双写是指同时将数据写入数据库和缓存中，但由于网络延迟或者系统故障等原因，可能导致双写操作的不一致性
- 解决方案：
  - 方法一：异步刷新：先写入数据库，再将数据异步写入缓存中，保证两个操作都成功完成或者都失败回滚
  - 方法二：一致性哈希：使用一致性哈希算法将数据分布到不同的节点上，保证同一份数据的副本存储在同一个节点上，避免双写操作的不一致性

#### 5.5 热点缓存

- 导致原因：
  - 热点缓存是指某些数据被频繁访问，导致这些数据成为系统的瓶颈
- 解决方案：
  - 方法一：本地缓存，在应用服务器上增加本地缓存，减少对远程缓存服务的访问次数
  - 方法二：限流处理，限制热点数据的访问频率，避免被恶意攻击或者被频繁访问导致系统崩溃

#### 5.6 缓存抖动

- 导致原因
  - 一般是由于网络不稳定或者节点故障等原因，导致缓存服务不可用，直接影响到系统的性能和稳定性
- 解决方案
  - 方法一：缓存降级，在缓存服务出现问题时，自动切换到备用节点或者降级处理，保证系统的稳定性和可用性
  - 方法二：负载均衡，通过负载均衡算法将请求分发到多个节点上，避免单个节点过载或者故障对系统造成影响

#### 5.7 缓存预热

- **缓存预热** 就是系统上线后，提前将相关的数据直接加载到缓存系统，这样用户可以直接查询事先被预热的缓存数据，为了避免在用户请求的时候，缓存为空，导致每次都需要先查询数据库，然后再将数据缓存，造成效率慢的问题
- 实现起来很简单，本质就是提前从硬盘或数据库中读取数据，或者预先计算好数据，并把它们放入到缓存中

## 6. 合理利用缓存

- 不合理使用缓存非但不能提高系统的性能，还会成为系统的累赘，甚至风险
- 频繁修改的数据
  - 如果缓存中保存的是频繁修改的数据，就会出现数据写入缓存后，应用还来不及读取缓存，数据就已经失效，徒增系统负担。一般来说，数据的读写比在 2：1（ 写入一次缓存，在数据更新前至少读取两次 ）以上，缓存才有意义
- 没有热点的访问
  - 如果应用系统访问数据没有热点，不遵循二八定律，那么缓存就没有意义
- 数据不一致与脏读
  - 一般会对缓存的数据设置失效时间，一旦超过失效时间，就要从数据库中重新加载。因此要容忍一定时间的数据不一致，如卖家已经编辑了商品属性，但是需要过一段时间才能被买家看到
  - 还有一种策略是数据更新立即更新缓存，不过这也会带来更多系统开销和事务一致性问题
- 缓存可用性
  - 缓存会承担大部分数据库访问压力，数据库已经习惯了有缓存的日子，所以当缓存服务崩溃时，数据库会因为完全不能承受如此大压力而宕机，导致网站不可用。这种情况被称作缓存雪崩，发生这种故障，甚至不能简单地重启缓存服务器和数据库服务器来恢复
  - 实践中，有的网站通过缓存热备份等手段提高缓存可用性：
    - 当某台缓存服务器宕机时，将缓存访问切换到热备服务器上。但这种设计有违缓存的初衷，缓存根本就不应该当做一个可靠的数据源来使用
    - 通过分布式缓存服务器集群，将缓存数据分布到集群多台服务器上可在一定程度上改善缓存的可用性。当一台缓存服务器宕机时，只有部分缓存数据丢失，重新从数据库加载这部分数据不会产生很大的影响

## 7. 布隆过滤器（ Bloom Filter，BF ）

- 布隆过滤器主要是为了解决海量数据的存在性问题。对于海量数据中判定某个数据是否存在且容忍轻微误差这一场景（ 比如缓存穿透、海量数据去重 ）来说，非常适合

#### 7.1 基础介绍

- 布隆过滤器是一个 Bloom 于 1970 年提出的。可以把它看作由二进制向量（ 或者说位数组 ）和一系列随机映射函数（ 哈希函数 ）两部分组成的数据结构
  ![image](https://github.com/user-attachments/assets/f3efb44c-4f80-48c4-bb50-0194e8105ec3)
- 相比于我们平时常用的 List、Map、Set 等数据结构，它占用空间更少并且效率更高，但是缺点是其返回的结果是概率性的，而不是非常准确的。理论情况下添加到集合中的元素越多，误报的可能性就越大
- 并且，存放在布隆过滤器的数据不容易删除。Bloom Filter 会使用一个较大的 bit 数组来保存所有的数据，数组中的每个元素都只占用 1 bit，并且每个元素只能是 0 或者 1（ 代表 false 或者 true ），这也是 Bloom Filter 节省内存的核心所在
- 这样来算的话，申请一个 100w 个元素的位数组只占用 1000000 Bit / 8 = 125000 Byte = 125000 / 1024 KB ≈ 122KB 的空间

#### 7.2 原理介绍

- 先初始化一个位数组，所有位置均为 0
- 当一个元素加入布隆过滤器中的时候，会进行如下操作：
  - 使用布隆过滤器中的 **多个哈希函数** 对元素值进行计算，得到哈希值（ 有几个哈希函数得到几个哈希值 ）
  - 根据得到的哈希值，在位数组中把对应下标的值置为 1
- 当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行如下操作：
  - 对给定元素再次进行相同的哈希计算
  - 得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中
- 不同的字符串可能哈希出来的位置相同，这种情况我们可以适当增加位数组大小或者调整我们的哈希函数
- Bloom Filter 的简单原理图如下
  ![image](https://github.com/user-attachments/assets/fe5410f5-3620-4b8b-bee2-e07e18475bf2)

#### 7.3 使用场景

- 判断给定数据是否存在：
  - 比如判断一个数字是否存在于包含大量数字的数字集中（ 数字集很大，上亿 ）
  - 防止缓存穿透（ 判断请求的数据是否有效避免直接绕过缓存请求数据库 ）
  - 邮箱的垃圾邮件过滤（ 判断一个邮件地址是否在垃圾邮件列表中 ）
  - 黑名单功能（ 判断一个 IP 地址或手机号码是否在黑名单中 ）
  - 防止重复添加，比如对巨量的 订单号 去重
